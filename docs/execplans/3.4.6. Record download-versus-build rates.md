# Record download-versus-build rates and total installation time (3.4.6)

This Execution Plan (ExecPlan) is a living document. The sections
`Constraints`, `Tolerances`, `Risks`, `Progress`, `Surprises & Discoveries`,
`Decision Log`, and `Outcomes & Retrospective` must be kept up to date as work
proceeds.

Status: COMPLETE

This document must be maintained in accordance with `AGENTS.md`.

The canonical plan file is
`docs/execplans/3.4.6. Record download-versus-build rates.md`.

## Purpose / big picture

Roadmap item 3.4.6 requires the installer to record how often installation
succeeds through prebuilt download versus local build, and to record overall
installation duration so migration outcomes from ADR-001 can be measured.

After this work, each successful non-dry-run install will persist one local
metric event and update aggregated counters. The installer will surface a short
summary showing:

- download rate (fraction of installs that used prebuilt artefacts);
- build rate (fraction of installs that built locally, including fallback);
- total installation time accumulated across recorded installs.

Success is observable by:

1. Unit tests proving counters, rate calculation, duration accumulation,
   file persistence, and recovery from malformed metrics files.
2. Behaviour tests using `rstest-bdd` v0.5.0 covering happy paths,
   unhappy paths, and edge cases.
3. `make check-fmt`, `make lint`, and `make test` succeeding.
4. Design decision updates captured in
   `docs/whitaker-dylint-suite-design.md`.
5. `docs/roadmap.md` item 3.4.6 marked done after all gates pass.

## Constraints

- Keep prebuilt failures non-fatal; fallback-to-build semantics from 3.4.4/3.4.5
  must remain unchanged.
- Metrics must be local-only data under `BaseDirs::whitaker_data_dir()`; no
  network telemetry or external reporting.
- Dry-run mode must not write metrics.
- Record metrics only for successful install completion to avoid skew from
  early-failing runs that never stage libraries.
- Use semantic errors internally, but metric write/read problems must degrade
  gracefully to warnings and must not fail installation.
- Add unit and behaviour coverage for happy, unhappy, and relevant edge cases.
- Behaviour tests must use `rstest-bdd` v0.5.0 patterns already used in
  `installer/tests/`.
- Keep files below 400 lines; split modules/tests when needed.
- Use en-GB-oxendict spelling in docs/comments.
- Keep dependency policy unchanged (caret requirements only; no wildcard/open
  ranges).

## Tolerances (exception triggers)

- Scope: if implementation exceeds 14 files changed or 500 net LOC, stop and
  escalate.
- Interfaces: if completion requires breaking existing public CLI flags or
  changing `PrebuiltResult` semantics, stop and escalate.
- Dependencies: if a new external crate is needed beyond the current workspace,
  stop and escalate.
- Iterations: if quality gates fail after 5 fix cycles, stop and escalate with
  options.
- Ambiguity: if "record rates" must include failed installs or partial runs,
  stop and confirm policy before proceeding.

## Risks

- Risk: ambiguous interpretation of "download-versus-build rates".
  Severity: medium. Likelihood: medium. Mitigation: explicitly define
  denominator as successful installs and record this decision in the design
  document.

- Risk: metrics file corruption or manual edits causing parse failures.
  Severity: medium. Likelihood: medium. Mitigation: implement resilient load
  path with reset-to-default and warning.

- Risk: metrics persistence failures on read-only filesystems.
  Severity: medium. Likelihood: low. Mitigation: treat persistence as
  best-effort; continue installation and warn.

- Risk: duration measurement becoming inconsistent across code paths.
  Severity: low. Likelihood: medium. Mitigation: measure once in `run_install`
  around install orchestration and feed a single terminal outcome into metrics
  recorder.

## Progress

- [x] (2026-02-21 00:00Z) Drafted ExecPlan for roadmap item 3.4.6.
- [x] (2026-02-21 12:10Z) Finalized metric model and persistence format.
- [x] (2026-02-21 12:20Z) Implemented installer orchestration instrumentation.
- [x] (2026-02-21 12:35Z) Added unit coverage for metrics model and integration.
- [x] (2026-02-21 12:45Z) Added `rstest-bdd` behaviour coverage.
- [x] (2026-02-21 12:50Z) Updated design docs and roadmap.
- [x] (2026-02-21 13:35Z) Ran quality gates and captured evidence.

## Surprises & discoveries

- No existing installer metrics module or persisted install-statistics file
  exists; this feature is net-new in `installer/`.
- Existing behaviour tests already isolate prebuilt/build decisions via stubs,
  which is the fastest place to add BDD assertions for this task.
- `make test` can take over 20 minutes in this environment due long-running UI
  and behavioural scenarios, so log capture and patient polling are required.

## Decision log

- Decision: Persist aggregated installer metrics in a local JSON file under
  Whitaker's data directory, and update it after successful installs.
  Rationale: satisfies ADR migration measurement without adding external
  telemetry and keeps privacy-preserving local observability. Date/Author:
  2026-02-21 (agent).

- Decision: Define rates over successful completed installs only.
  Rationale: avoids denominator ambiguity and keeps reported rates aligned with
  observed end-user outcomes. Date/Author: 2026-02-21 (agent).

- Decision: Treat metrics read/write failures as non-fatal warnings.
  Rationale: installer reliability is a higher-priority invariant than
  telemetry completeness. Date/Author: 2026-02-21 (agent).

## Outcomes & retrospective

Implemented and validated.

Delivered outcomes:

- Added `installer/src/install_metrics.rs` with:
  - local JSON persistence at `<data_dir>/metrics/install_metrics.json`,
  - download/build counters and cumulative install duration,
  - rate calculations and summary-line formatting,
  - corrupt-file recovery and non-fatal persistence error handling.
- Integrated metrics recording into successful install completion paths in
  `installer/src/main.rs` for both prebuilt-download and local-build outcomes.
- Added unit tests for:
  - zero-state rates,
  - count/duration accumulation,
  - persistence creation and updates,
  - corrupt file recovery,
  - write failure handling,
  - summary output formatting.
- Added behavioural coverage with `rstest-bdd` v0.5.0 in:
  - `installer/tests/features/install_metrics.feature`,
  - `installer/tests/behaviour_install_metrics.rs`.
- Updated design and roadmap documentation:
  - `docs/whitaker-dylint-suite-design.md`,
  - `docs/roadmap.md` (3.4.6 marked done).
- Quality gates passed:
  - `make check-fmt`,
  - `make lint`,
  - `make test` (632 passed, 2 skipped).

## Context and orientation

Current relevant flow:

- `installer/src/main.rs` orchestrates install flow in `run_install()`, trying
  prebuilt first and falling back to local build.
- `installer/src/prebuilt.rs` provides prebuilt attempt outcome
  (`PrebuiltResult::Success` or `Fallback`).
- `installer/src/output.rs` already owns user-facing installer text helpers.
- `installer/src/dirs.rs` exposes `BaseDirs::whitaker_data_dir()` for
  platform-specific data storage roots.
- Unit tests for CLI orchestration live in `installer/src/tests.rs`.
- Behaviour tests are in `installer/tests/`, with feature files under
  `installer/tests/features/` and `rstest-bdd` scenario bindings in Rust.

Reference guidance to follow while implementing:

- `docs/adr-001-prebuilt-dylint-libraries.md`
- `docs/whitaker-dylint-suite-design.md`
- `docs/rust-testing-with-rstest-fixtures.md`
- `docs/rstest-bdd-users-guide.md`
- `docs/rust-doctest-dry-guide.md`
- `docs/complexity-antipatterns-and-refactoring-strategies.md`

## Plan of work

### Stage A: Define a metrics domain model and storage API

Introduce a focused installer metrics module for durable counters and timing.

Planned files:

- `installer/src/install_metrics.rs` (new)
- `installer/src/lib.rs` (module export)
- `installer/src/error.rs` (only if a narrowly-scoped internal error is needed)

Planned design:

- Add a serializable aggregate struct capturing:
  `total_installs`, `download_installs`, `build_installs`, and
  `total_install_millis`.
- Add pure methods for recording outcomes and computing rates.
- Add loader/saver helpers rooted at
  `<whitaker_data_dir>/metrics/install_metrics.json`.
- Keep storage interface testable by accepting explicit paths for unit tests.

Go/no-go validation:

- Unit tests confirm serialization round-trip, zero-safe rate calculations, and
  accumulation math.

### Stage B: Instrument installer orchestration

Record total install duration and terminal install mode in one place.

Planned files:

- `installer/src/main.rs`
- `installer/src/output.rs` (add summary formatting helper if needed)
- `installer/src/tests.rs`

Planned design:

- Capture `Instant::now()` at start of non-dry-run install path.
- Classify terminal mode:
  - `download`: prebuilt success path;
  - `build`: local compile path (explicit build-only or fallback).
- After successful `finish_install(...)`, update metrics store and emit a short
  summary line containing download rate, build rate, and cumulative install
  time.
- On metrics write failure, print a warning and continue returning success.

Go/no-go validation:

- Unit tests verify mode classification and that metrics update is skipped for
  dry-run and failed installs.

### Stage C: Add unit tests for happy, unhappy, and edge cases

Planned files:

- `installer/src/install_metrics.rs` (or split to
  `installer/src/install_metrics_tests.rs` if line count requires)
- `installer/src/tests.rs`

Required unit coverage:

- Happy: first successful download install creates metrics file and rates are
  `download=1.0`, `build=0.0`.
- Happy: subsequent build install updates counts and cumulative duration.
- Unhappy: malformed metrics JSON resets to defaults and still records current
  install.
- Unhappy: metrics file write failure returns warning path without aborting
  install.
- Edge: zero-record rates return `0.0` without divide-by-zero.
- Edge: large accumulated duration remains stable and does not overflow
  practical bounds.

### Stage D: Add behaviour tests with `rstest-bdd` v0.5.0

Planned files:

- `installer/tests/features/install_metrics.feature` (new)
- `installer/tests/behaviour_install_metrics.rs` (new)
- `installer/tests/features/prebuilt_download.feature` and
  `installer/tests/behaviour_prebuilt.rs` (extend if reuse is cleaner)

Required BDD scenarios:

- Happy: successful prebuilt path records one download install and updates total
  time.
- Happy: fallback/local-build path records one build install and updates total
  time.
- Unhappy: unreadable/corrupt prior metrics state is recovered and recording
  still proceeds.
- Unhappy: metrics persistence failure reports warning and install still
  completes.
- Edge: build-only path increments build count without prebuilt attempt.
- Edge: dry-run does not create or modify metrics data.

BDD implementation notes:

- Use mutable-world fixtures and step-definition style already used in existing
  installer behaviour suites.
- Keep assertions user-observable: summary text and persisted metrics state.

### Stage E: Record design decisions and roadmap completion

Planned files:

- `docs/whitaker-dylint-suite-design.md`
- `docs/roadmap.md`

Required updates:

- Add a design decision entry documenting:
  - local-only metrics storage location,
  - definition of denominator for rates,
  - non-fatal behaviour for metrics I/O failures.
- Mark roadmap item `3.4.6` as done only after tests and gates pass.

### Stage F: Quality gates and evidence capture

Run required checks with log capture:

    set -o pipefail; make check-fmt 2>&1 | tee /tmp/whitaker-check-fmt.log
    set -o pipefail; make lint 2>&1 | tee /tmp/whitaker-lint.log
    set -o pipefail; make test 2>&1 | tee /tmp/whitaker-test.log

If documentation files are changed during implementation, also run:

    set -o pipefail; make markdownlint 2>&1 | tee /tmp/whitaker-markdownlint.log
    set -o pipefail; make nixie 2>&1 | tee /tmp/whitaker-nixie.log

## Concrete steps

1. Create `install_metrics` module with aggregate model, read/write helpers, and
   pure update/rate methods.
2. Wire `run_install` instrumentation to measure duration and record final mode
   only after successful completion.
3. Add user-facing summary formatting helper and warning text for metrics I/O
   degradation.
4. Add unit tests for model math, parsing/writing, and orchestration branches.
5. Add `rstest-bdd` feature/scenario bindings for happy, unhappy, and edge
   flows.
6. Update design doc and mark roadmap item 3.4.6 done.
7. Run quality gates and keep command logs as evidence.

## Validation and acceptance

Acceptance criteria:

- Installer records aggregate metrics for successful installs and surfaces
  download/build rates and cumulative installation time.
- No regression in prebuilt fallback behaviour.
- Unit tests and BDD tests cover happy, unhappy, and edge paths.
- `make check-fmt`, `make lint`, and `make test` pass.
- Design decisions are documented and roadmap item 3.4.6 is marked done.

Expected observable checks after implementation:

- Running installer on a successful prebuilt path prints metrics summary with
  incremented download rate.
- Running installer with `--build-only` prints metrics summary with incremented
  build rate.
- Corrupting metrics file and running installer still succeeds, with warning and
  repaired metrics state.

## Idempotence and recovery

- Metrics updates are append-safe in the sense of repeated successful installs;
  each rerun increments counters deterministically.
- If metrics file is missing, recreate it from defaults.
- If metrics file is malformed, warn, reset to defaults, and continue.
- If metrics write fails, continue installation and log a warning; retry on next
  install.

## Artifacts and notes

During implementation, capture concise evidence snippets in this section:

- Metrics summary lines from installer output.
- Example persisted `install_metrics.json` after one download and one build run.
- Final quality-gate pass summaries from `/tmp/whitaker-*.log` files.

Evidence snapshot:

- `make check-fmt`: success.
- `make lint`: success.
- `make test`: `632 tests run: 632 passed, 2 skipped`.

## Interfaces and dependencies

Prescriptive target interfaces for the implementation phase:

- New module `crate::install_metrics` exposing:
  - an aggregate metrics type,
  - a terminal install-mode enum (`Download` / `Build`),
  - pure update/rate methods,
  - load/save helpers scoped to Whitaker data directory.
- `run_install` in `installer/src/main.rs` becomes the single source for:
  - duration capture,
  - install-mode classification,
  - post-success metrics recording.
- Use existing dependencies already present in workspace (`serde`,
  `serde_json`, `thiserror`, `camino`); do not add new external crates unless
  escalation is approved.

Revision note (2026-02-21): Implemented the full 3.4.6 feature, updated plan
status/progress to complete, and recorded final outcomes plus validation
evidence.
